{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset under consideration : WeRateDogs Twitter Data\n",
    "\n",
    "#### About WE RATE DOGS :\n",
    "The dataset that I will be wrangling (as well as analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "\n",
    "WeRateDogs downloaded their Twitter archive and sent it to Udacity to use in this project. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017.\n",
    "\n",
    "Main tasks in this project are as follows:\n",
    "\n",
    "1. Data wrangling, which consists of:\n",
    "\n",
    "    Gathering data\n",
    "\n",
    "    Assessing data\n",
    "    \n",
    "    Cleaning data\n",
    "    \n",
    "\n",
    "2. Storing, analyzing, and visualizing your wrangled data\n",
    "\n",
    "\n",
    "3. Reporting on:\n",
    "    \n",
    "    Data wrangling efforts \n",
    "    \n",
    "    Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import wptools\n",
    "import os\n",
    "import requests as rt\n",
    "import tweepy\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "df = pd.read_csv(\"twitter-archive-enhanced.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'HIDDEN'\n",
    "consumer_secret = 'HIDDEN'\n",
    "access_token = 'HIDDEN'\n",
    "access_secret = 'HIDDEN'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n",
    "# df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n",
    "# change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n",
    "# NOTE TO REVIEWER: this student had mobile verification issues so the following\n",
    "# Twitter API code was sent to this student from a Udacity instructor\n",
    "# Tweet IDs for which to gather additional data via Twitter's API\n",
    "tweet_ids = df_1.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making directory if it doesn't already exist \n",
    "folder_name = 'image_predictions'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    \n",
    "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "response = rt.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the file \n",
    "with open(os.path.join(folder_name,\n",
    "                      url.split('/')[-1]) , mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the file \n",
    "image_predictions = pd.read_csv(r\"C:\\Users\\CLOUDVIEW\\Downloads\\ALX Udacity\\image-predictions.tsv\" , sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening json file\n",
    "df_list = []\n",
    "with open(r\"C:\\Users\\CLOUDVIEW\\Downloads\\ALX Udacity\\tweet-json.txt\") as file:\n",
    "    for line in file:\n",
    "        df_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading json file data\n",
    "tweets = pd.DataFrame(df_list , columns = ['id' , 'retweet_count' , 'favorite_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. I used **both** visual assessment and programmatic assessement to assess the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first five rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random selection of 5 rows in the dataframe\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a concise summary of the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of duplicates in the data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return counts of unique values of the rating_denominator\n",
    "df.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return counts of unique values of the rating_numerator\n",
    "df.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return counts of unique values in the name column\n",
    "df.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the datatype\n",
    "type(df.timestamp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows and columns\n",
    "print(\"The rows and column in this dataset are (Rows,Columns) : \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first five rows of the dataframe\n",
    "image_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a concise summary of the DataFrame\n",
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of duplicates in the data\n",
    "image_predictions.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows and columns\n",
    "print(\"The rows and column in this dataset are (Rows,Columns) : \",image_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first five rows of the dataframe\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a concise summary of the DataFrame\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of duplicates in the data\n",
    "tweets.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows and columns\n",
    "print(\"The rows and column in this dataset are (Rows,Columns) : \",tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "\n",
    "#### 1. Twitter-archive-enhanced table\n",
    "\n",
    "a. There are some tweets in twitter-archive dataframe that have no images\n",
    "\n",
    "b. Some values in rating denominator are != 10 \n",
    "\n",
    "c. Some values in rating numerator contain decimals\n",
    "\n",
    "d. Timestamp should be date-time not string\n",
    "\n",
    "e. Nulls represented as none in name column\n",
    "\n",
    "f. There are 59 missing values in expanded_urls column\n",
    "\n",
    "g. The tweet_id should be \"string\" not \"int\"\n",
    "\n",
    "h. Strange names like 'a','his', etc. in name column\n",
    "\n",
    "i. The retweeted_status_id column should be removed as it's not needed \n",
    "\n",
    "j. The retweeted_status_user_id column should be removed as it's not needed \n",
    "\n",
    "k. The retweeted_status_timestamp column should be removed as it's not needed \n",
    "\n",
    "l. The in_reply_to_status_id column should be removed as it is not needed\n",
    "\n",
    "m. The in_reply_to_user_id column should be removed as it is not needed\n",
    "\n",
    "n. Keep only original tweets\n",
    "\n",
    "\n",
    "\n",
    "#### 2.  Image_predictions table\n",
    "\n",
    "a. The p1, p2, p3 columns have some names in upper case and some in lower case\n",
    "\n",
    "b. Missing id records there are 2075 instead of 2356\n",
    "\n",
    "c. The tweet_id should be \"string\" not \"int\"\n",
    "\n",
    "\n",
    "#### 3. Tweets table\n",
    "\n",
    "a. Id column name should be tweet_id instead of id\n",
    "\n",
    "b. Missing records there are 2354 instead of 2356\n",
    "\n",
    "c. The tweet_id should be \"string\" not \"int\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1. The doggo, floofer, pupper, and puppo column should be in one column not four\n",
    "\n",
    "\n",
    "2. The three dataframes should be combined into one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, I cleaned **all** of the issues I documented while assessing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copies of original pieces of data\n",
    "#create a copy from each data frame to be used in cleaning processes and keep original one as it is\n",
    "df_clean = df.copy()\n",
    "img_pred_clean = image_predictions.copy()\n",
    "tweets_clean = tweets.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1:\n",
    "Nulls represented as none in name column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Replace the none values with nulls using replace method and numpy nan method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a               55\n",
       "actually         2\n",
       "all              1\n",
       "an               7\n",
       "by               1\n",
       "getting          2\n",
       "his              1\n",
       "incredibly       1\n",
       "infuriating      1\n",
       "just             4\n",
       "life             1\n",
       "light            1\n",
       "mad              2\n",
       "my               1\n",
       "not              2\n",
       "officially       1\n",
       "old              1\n",
       "one              4\n",
       "quite            4\n",
       "space            1\n",
       "such             1\n",
       "the              8\n",
       "this             1\n",
       "unacceptable     1\n",
       "very             5\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df_clean.name.str.contains('^[a-z]', regex = True)\n",
    "df_clean[mask].name.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.loc[df_clean.name.str.islower(),'name']='None'\n",
    "df_clean.name = df_clean.name.replace('None', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Charlie       12\n",
       "Lucy          11\n",
       "Cooper        11\n",
       "Oliver        11\n",
       "Lola          10\n",
       "              ..\n",
       "Dev√≥n          1\n",
       "Gert           1\n",
       "Dex            1\n",
       "Ace            1\n",
       "Christoper     1\n",
       "Name: name, Length: 931, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check names value counts\n",
    "df_clean['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: name, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[mask].name.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2:\n",
    "Keep only original tweets, no retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Define\n",
    " keep original ratings (no retweets) that have images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude all the retweets by filtering \n",
    "df_clean = df_clean[df_clean['retweeted_status_user_id'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2175 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2175 non-null   int64  \n",
      " 1   in_reply_to_status_id       78 non-null     float64\n",
      " 2   in_reply_to_user_id         78 non-null     float64\n",
      " 3   timestamp                   2175 non-null   object \n",
      " 4   source                      2175 non-null   object \n",
      " 5   text                        2175 non-null   object \n",
      " 6   retweeted_status_id         0 non-null      float64\n",
      " 7   retweeted_status_user_id    0 non-null      float64\n",
      " 8   retweeted_status_timestamp  0 non-null      object \n",
      " 9   expanded_urls               2117 non-null   object \n",
      " 10  rating_numerator            2175 non-null   int64  \n",
      " 11  rating_denominator          2175 non-null   int64  \n",
      " 12  name                        1391 non-null   object \n",
      " 13  doggo                       2175 non-null   object \n",
      " 14  floofer                     2175 non-null   object \n",
      " 15  pupper                      2175 non-null   object \n",
      " 16  puppo                       2175 non-null   object \n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 305.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#check retweeted_status_user_id have any retweet\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:\n",
    "Some values in rating_denominator column are != 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "Identify and drop all tweets that have \"rating_denominator\" != 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>@jonnysun @Lin_Manuel ok jomny I know you're e...</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>@docmisterio account started on 11/15/15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>The floofs have been released I repeat the flo...</td>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Meet Sam. She smiles 24/7 &amp;amp; secretly aspir...</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Why does this never happen at my front door......</td>\n",
       "      <td>165</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>After so many requests, this is Bretagne. She ...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>Say hello to this unbelievably well behaved sq...</td>\n",
       "      <td>204</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>Happy 4/20 from the squad! 13/10 for all https...</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>This is Bluebert. He just saw that both #Final...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>Happy Saturday here's 9 puppers on a bench. 99...</td>\n",
       "      <td>99</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Here's a brigade of puppers. All look very pre...</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>From left to right:\\nCletus, Jerome, Alejandro...</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>Here is a whole flock of puppers.  60/50 I'll ...</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>Happy Wednesday here's a bucket of pups. 44/40...</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>Yes I do realize a rating of 4/20 would've bee...</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>Two sneaky puppers were not initially seen, mo...</td>\n",
       "      <td>143</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>Someone help the girl is being mugged. Several...</td>\n",
       "      <td>121</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>This is Darrel. He just robbed a 7/11 and is i...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>I'm aware that I could've said 20/16, but here...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>IT'S PUPPERGEDDON. Total of 144/120 ...I think...</td>\n",
       "      <td>144</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>Here we have an entire platoon of puppers. Tot...</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>This is an Albanian 3 1/2 legged  Episcopalian...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  rating_numerator  \\\n",
       "313   @jonnysun @Lin_Manuel ok jomny I know you're e...               960   \n",
       "342            @docmisterio account started on 11/15/15                11   \n",
       "433   The floofs have been released I repeat the flo...                84   \n",
       "516   Meet Sam. She smiles 24/7 &amp; secretly aspir...                24   \n",
       "902   Why does this never happen at my front door......               165   \n",
       "1068  After so many requests, this is Bretagne. She ...                 9   \n",
       "1120  Say hello to this unbelievably well behaved sq...               204   \n",
       "1165  Happy 4/20 from the squad! 13/10 for all https...                 4   \n",
       "1202  This is Bluebert. He just saw that both #Final...                50   \n",
       "1228  Happy Saturday here's 9 puppers on a bench. 99...                99   \n",
       "1254  Here's a brigade of puppers. All look very pre...                80   \n",
       "1274  From left to right:\\nCletus, Jerome, Alejandro...                45   \n",
       "1351  Here is a whole flock of puppers.  60/50 I'll ...                60   \n",
       "1433  Happy Wednesday here's a bucket of pups. 44/40...                44   \n",
       "1598  Yes I do realize a rating of 4/20 would've bee...                 4   \n",
       "1634  Two sneaky puppers were not initially seen, mo...               143   \n",
       "1635  Someone help the girl is being mugged. Several...               121   \n",
       "1662  This is Darrel. He just robbed a 7/11 and is i...                 7   \n",
       "1663  I'm aware that I could've said 20/16, but here...                20   \n",
       "1779  IT'S PUPPERGEDDON. Total of 144/120 ...I think...               144   \n",
       "1843  Here we have an entire platoon of puppers. Tot...                88   \n",
       "2335  This is an Albanian 3 1/2 legged  Episcopalian...                 1   \n",
       "\n",
       "      rating_denominator  \n",
       "313                    0  \n",
       "342                   15  \n",
       "433                   70  \n",
       "516                    7  \n",
       "902                  150  \n",
       "1068                  11  \n",
       "1120                 170  \n",
       "1165                  20  \n",
       "1202                  50  \n",
       "1228                  90  \n",
       "1254                  80  \n",
       "1274                  50  \n",
       "1351                  50  \n",
       "1433                  40  \n",
       "1598                  20  \n",
       "1634                 130  \n",
       "1635                 110  \n",
       "1662                  11  \n",
       "1663                  16  \n",
       "1779                 120  \n",
       "1843                  80  \n",
       "2335                   2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show records where rating_denominator != 10 \n",
    "df_clean[df_clean['rating_denominator'] != 10][['text','rating_numerator', 'rating_denominator' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is an Albanian 3 1/2 legged  Episcopalian. Loves well-polished hardwood flooring. Penis on the collar. 9/10 https://t.co/d9NcXFKwLv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix record (2335)\n",
    "df_clean[df_clean['rating_denominator'] != 10].loc[2335,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix denominator and numerator values for record (2335)\n",
    "df_clean.loc[2335 , 'rating_denominator'] = 10\n",
    "df_clean.loc[2335 , 'rating_numerator'] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify all tweets that have rating_denominator != 10 \n",
    "wrong_denom = df_clean[df_clean['rating_denominator'] != 10].index\n",
    "\n",
    "#drop all tweets that have rating_denominator != 10 \n",
    "df_clean.drop(wrong_denom , inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                                                     666287406224695296\n",
       "in_reply_to_status_id                                                       NaN\n",
       "in_reply_to_user_id                                                         NaN\n",
       "timestamp                                             2015-11-16 16:11:11 +0000\n",
       "source                        <a href=\"http://twitter.com/download/iphone\" r...\n",
       "text                          This is an Albanian 3 1/2 legged  Episcopalian...\n",
       "retweeted_status_id                                                         NaN\n",
       "retweeted_status_user_id                                                    NaN\n",
       "retweeted_status_timestamp                                                  NaN\n",
       "expanded_urls                 https://twitter.com/dog_rates/status/666287406...\n",
       "rating_numerator                                                              9\n",
       "rating_denominator                                                           10\n",
       "name                                                                        NaN\n",
       "doggo                                                                      None\n",
       "floofer                                                                    None\n",
       "pupper                                                                     None\n",
       "puppo                                                                      None\n",
       "Name: 2335, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm that record(2335) has been fixed\n",
    "df_clean.loc[2335,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_id, in_reply_to_status_id, in_reply_to_user_id, timestamp, source, text, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls, rating_numerator, rating_denominator, name, doggo, floofer, pupper, puppo]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that all tweets that have rating_denominator != 10 have been removed\n",
    "df_clean[df_clean['rating_denominator'] != 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4:\n",
    "Some val4es in rating numerator contain decimals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Fix the numerators containing decimal values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CLOUDVIEW\\AppData\\Local\\Temp\\ipykernel_8912\\2486936526.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_clean[df_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")][['tweet_id', 'text', 'rating_numerator', 'rating_denominator']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>883482846933004288</td>\n",
       "      <td>This is Bella. She hopes her smile made you sm...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>786709082849828864</td>\n",
       "      <td>This is Logan, the Chow who lived. He solemnly...</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>778027034220126208</td>\n",
       "      <td>This is Sophie. She's a Jubilant Bush Pupper. ...</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>681340665377193984</td>\n",
       "      <td>I've been told there's a slight possibility he...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>680494726643068929</td>\n",
       "      <td>Here we have uncovered an entire battalion of ...</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "45    883482846933004288  This is Bella. She hopes her smile made you sm...   \n",
       "695   786709082849828864  This is Logan, the Chow who lived. He solemnly...   \n",
       "763   778027034220126208  This is Sophie. She's a Jubilant Bush Pupper. ...   \n",
       "1689  681340665377193984  I've been told there's a slight possibility he...   \n",
       "1712  680494726643068929  Here we have uncovered an entire battalion of ...   \n",
       "\n",
       "      rating_numerator  rating_denominator  \n",
       "45                   5                  10  \n",
       "695                 75                  10  \n",
       "763                 27                  10  \n",
       "1689                 5                  10  \n",
       "1712                26                  10  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")][['tweet_id', 'text', 'rating_numerator', 'rating_denominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to float datatype\n",
    "df_clean[['rating_numerator', 'rating_denominator']] = df_clean[['rating_numerator','rating_denominator']].astype(float)\n",
    "\n",
    "#update values\n",
    "df_clean.loc[(df_clean.tweet_id == 883482846933004288), 'rating_numerator'] = 13.5\n",
    "df_clean.loc[(df_clean.tweet_id == 786709082849828864), 'rating_numerator'] = 9.75\n",
    "df_clean.loc[(df_clean.tweet_id == 778027034220126208), 'rating_numerator'] = 11.27\n",
    "df_clean.loc[(df_clean.tweet_id == 681340665377193984), 'rating_numerator'] = 9.5\n",
    "df_clean.loc[(df_clean.tweet_id == 680494726643068929), 'rating_numerator'] = 11.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CLOUDVIEW\\AppData\\Local\\Temp\\ipykernel_8912\\1431920438.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_clean[df_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")][['tweet_id', 'text', 'rating_numerator', 'rating_denominator']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>883482846933004288</td>\n",
       "      <td>This is Bella. She hopes her smile made you sm...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>786709082849828864</td>\n",
       "      <td>This is Logan, the Chow who lived. He solemnly...</td>\n",
       "      <td>9.75</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>778027034220126208</td>\n",
       "      <td>This is Sophie. She's a Jubilant Bush Pupper. ...</td>\n",
       "      <td>11.27</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>681340665377193984</td>\n",
       "      <td>I've been told there's a slight possibility he...</td>\n",
       "      <td>9.50</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>680494726643068929</td>\n",
       "      <td>Here we have uncovered an entire battalion of ...</td>\n",
       "      <td>11.26</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "45    883482846933004288  This is Bella. She hopes her smile made you sm...   \n",
       "695   786709082849828864  This is Logan, the Chow who lived. He solemnly...   \n",
       "763   778027034220126208  This is Sophie. She's a Jubilant Bush Pupper. ...   \n",
       "1689  681340665377193984  I've been told there's a slight possibility he...   \n",
       "1712  680494726643068929  Here we have uncovered an entire battalion of ...   \n",
       "\n",
       "      rating_numerator  rating_denominator  \n",
       "45               13.50                10.0  \n",
       "695               9.75                10.0  \n",
       "763              11.27                10.0  \n",
       "1689              9.50                10.0  \n",
       "1712             11.26                10.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that tweets having rating_numerator more than 15 has been fixed:\n",
    "df_clean[df_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")][['tweet_id', 'text', 'rating_numerator', 'rating_denominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2154.000000\n",
       "mean       12.210901\n",
       "std        42.645417\n",
       "min         0.000000\n",
       "25%        10.000000\n",
       "50%        11.000000\n",
       "75%        12.000000\n",
       "max      1776.000000\n",
       "Name: rating_numerator, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check statistical summary of rating_numerator\n",
    "df_clean['rating_numerator'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #5:\n",
    "Timestamp should be \"date time\" not \"str\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Convert the column type using to_datetime method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert timestamp from str to datetime\n",
    "df_clean['timestamp']= pd.to_datetime(df_clean['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm that it has been converted\n",
    "type(df_clean['timestamp'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #6: \n",
    "\n",
    "There are some tweets in twitter-archive dataframe that have no images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Filter dataframe to have only tweets with images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the number of tweets in twitter-archive is equal to the number of tweets that have images in image_predictions\n",
    "df_clean['tweet_id'].size == df_clean.isin(image_predictions['tweet_id']).sum()['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter twitter-archive to only have tweets with images in image_predictions dataframe\n",
    "df_clean = df_clean[df_clean['tweet_id'].isin(image_predictions['tweet_id'].unique())]\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm that all tweets in twitter_archive have images in image_predictions\n",
    "df_clean['tweet_id'].size == df_clean['tweet_id'].isin(image_predictions['tweet_id']).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #7:\n",
    "retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, in_reply_to_status_id, in_reply_to_user_id should be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "These columns should be removed using the drop method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.drop(columns=['retweeted_status_id' , 'retweeted_status_user_id' , 'retweeted_status_timestamp', 'in_reply_to_status_id' , 'in_reply_to_user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm that columns have been dropped\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #8:\n",
    "The columns doggo, floofer, pupper, and puppo should be in one column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Create a new column 'dog_stage', extract dog stage from the four original columns then drop the original columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns 'doggo', 'floofer', 'pupper', 'puppo' should be merged in one column called 'dog_stage'\n",
    "df_clean['dog_stage'] = df_clean['text'].str.extract('(doggo|floofer|pupper|puppo)')\n",
    "#drop 'doggo', 'puppo', 'pupper', 'floofer' columns\n",
    "df_clean = df_clean.drop(columns=['doggo','floofer','pupper','puppo'])\n",
    "# use np.nan to fill the empty\n",
    "df_clean['dog_stage'] = df_clean['dog_stage'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that a new column 'dog_stage' has been created \n",
    "df_clean['dog_stage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #9:\n",
    "Values in p columns have some upper letter values and some lower letter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Make the first letters capital with title method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_clean.p1 = img_pred_clean.p1.str.title()\n",
    "img_pred_clean.p2 = img_pred_clean.p2.str.title()\n",
    "img_pred_clean.p3 = img_pred_clean.p3.str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm that values in columns have title case\n",
    "img_pred_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #10:\n",
    "id column should be tweet_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Replace the name of column from \"id\" to \"tweet_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column name to \"id\" in tweets_clean to \"tweet_id\" to be consistent with other two data frames when we merge\n",
    "tweets_clean.rename(columns={'id': 'tweet_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that name of \"id\" column has been changed to \"tweet_id\"\n",
    "tweets_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #11:\n",
    "tweet_id should be \"string\" not \"int\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Convert column type with astype method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['tweet_id'] = df_clean['tweet_id'].astype(str)\n",
    "img_pred_clean['tweet_id'] = img_pred_clean['tweet_id'].astype(str)\n",
    "tweets_clean['tweet_id'] = tweets_clean['tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_clean['tweet_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img_pred_clean['tweet_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tweets_clean['tweet_id'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #12:\n",
    "df_clean, image_predictions_clean and tweets_clean should be merged into one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Merge the three dataframe, joining on tweet_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "df_clean = pd.merge(df_clean, img_pred_clean , on= \"tweet_id\" , how=\"left\") \n",
    "df_clean = pd.merge(df_clean, tweets_clean, on= \"tweet_id\" , how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm that the dataframes have merged\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save our cleaned dataframe as CSV file\n",
    "df_clean.to_csv('twitter_archive_master.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clean = pd.read_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1. The Golden Retriever is the most popular breed \n",
    "\n",
    "2. The pupper stage is the most popular dog stage\n",
    "\n",
    "3. Afghan_hound got the highest average count of favorites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What breed is most popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "ax = sns.barplot(x = all_clean['p1'].value_counts()[0:10].index,\n",
    "            y = all_clean['p1'].value_counts()[0:10],\n",
    "            data = all_clean);\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90, fontsize = 15);\n",
    "plt.xlabel(\"Dog Breeds\",fontsize = 18);\n",
    "plt.ylabel(\"Prediction Count\",fontsize = 18);\n",
    "plt.title(\"Popular Dog Breeds\",fontsize = 18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Counts of Most Popular dog breed - Golden Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe for golden_retriever\n",
    "golden_df = all_clean.query('p1 == \"Golden_Retriever\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_df.sort_values('p1_conf',ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#first best Golden Retriever probability with high confidence \n",
    "url = all_clean.jpg_url[539]\n",
    "breed = rt.get(url)\n",
    "Image.open(BytesIO(breed.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second best Golden Retriever probability with high confidence \n",
    "url = all_clean.jpg_url[1799]\n",
    "breed = rt.get(url)\n",
    "Image.open(BytesIO(breed.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#third best Golden Retriever probability with high confidence \n",
    "url = all_clean.jpg_url[923]\n",
    "breed = rt.get(url)\n",
    "Image.open(BytesIO(breed.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What dog stage is the most popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "ax = sns.barplot(x = all_clean['dog_stage'].value_counts()[0:10].index,\n",
    "            y = all_clean['dog_stage'].value_counts()[0:10],\n",
    "            data = all_clean);\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation = 90, fontsize = 15);\n",
    "plt.xlabel(\"Dog stage\",fontsize = 18);\n",
    "plt.ylabel(\"Count\",fontsize = 18);\n",
    "plt.title(\"Popular Dog stage\",fontsize = 18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Counts of Most Popular Dog Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which tweet id and photo got more likes\n",
    "favorite = all_clean.sort_values('favorite_count',ascending=False);\n",
    "favorite = favorite[['tweet_id','favorite_count','jpg_url','dog_stage','p1']]\n",
    "favorite.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first high favorite for dog stage puppo \n",
    "url = all_clean.jpg_url[309]\n",
    "breed = rt.get(url)\n",
    "Image.open(BytesIO(breed.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first high favorite for dog stage doggo \n",
    "url = all_clean.jpg_url[771]\n",
    "breed = rt.get(url)\n",
    "Image.open(BytesIO(breed.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first high favorite for dog stage pupper\n",
    "url = all_clean.jpg_url[108]\n",
    "breed = rt.get(url)\n",
    "Image.open(BytesIO(breed.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What breed got the highest average number of favourites?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show out top 10 breeds having highest average number of favorites\n",
    "favourites = all_clean.groupby('p1')['favorite_count'].mean()[0:10].sort_values(ascending=False)\n",
    "favourites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "ax = sns.barplot(x = favourites.index,\n",
    "            y = all_clean.groupby('p1')['favorite_count'].mean()[0:10].sort_values(ascending=False));\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 90, fontsize = 15);\n",
    "plt.xlabel(\"Breeds\",fontsize = 18);\n",
    "plt.ylabel(\"Average Favourites count\", fontsize = 18);\n",
    "plt.title(\"Dog's Breed VS Average favorites count\", fontsize = 18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top count of breed with highest average number of favourites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe for afghan_hound\n",
    "breed_afghan = all_clean.query('p1 == \"Afghan_Hound\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_afghan.sort_values('p1_conf',ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the highest average favourite count for Afghan_hound\n",
    "url = all_clean.jpg_url[207]\n",
    "breed = rt.get(url)\n",
    "Image.open(BytesIO(breed.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe for African_Crocodile \n",
    "breed_croc = all_clean.query('p1 == \"African_Crocodile\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_croc.sort_values('p1_conf',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the highest average favourite count for Afghan_hound\n",
    "url = all_clean.jpg_url[1531]\n",
    "breed = rt.get(url)\n",
    "Image.open(BytesIO(breed.content))"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
